{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a5f8bf4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data from  addferti-rostock-soil-moisture\n",
      "URL: https://eu1.cloud.thethings.network/api/v3/as/applications/addferti-rostock-soil-moisture/packages/storage/uplink_message?order=-received_at&limit=100&field_mask=up.uplink_message.decoded_payload,up.uplink_message.locations\n",
      "Status: 200\n",
      "\n",
      "Fetching data from  addferti-bursa-soil-moisture\n",
      "URL: https://eu1.cloud.thethings.network/api/v3/as/applications/addferti-bursa-soil-moisture/packages/storage/uplink_message?order=-received_at&limit=100&field_mask=up.uplink_message.decoded_payload,up.uplink_message.locations\n",
      "Status: 200\n",
      "\n",
      "Fetching data from  addferti-ugent-soil-moisture\n",
      "URL: https://eu1.cloud.thethings.network/api/v3/as/applications/addferti-ugent-soil-moisture/packages/storage/uplink_message?order=-received_at&limit=100&field_mask=up.uplink_message.decoded_payload,up.uplink_message.locations\n",
      "Status: 200\n",
      "Value Error. No Data from TTN to fetch for ugent_soil_moisture\n",
      "exporting: current_ru_soil_moisture.shp\n",
      "exporting: current_bursa_soil_moisture.shp\n",
      "ugent_soil_moisture table not available.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "#run the first time only to create the table:\n",
    "\n",
    "# Before running this script:\n",
    "# --pandas version >1.4.0 needs to be installed\n",
    "# --create postgresql database 'addferti_lorawan\n",
    "\n",
    "# Postgres:\n",
    "postgreSQLTable = ['ru_soil_moisture','bursa_soil_moisture','ugent_soil_moisture']\n",
    "alchemyEngine   = create_engine('postgresql+psycopg2://postgres:postgres@127.0.0.1:5432/addferti_lorawan', pool_recycle=3600);\n",
    "                # create_engine(dialect+driver://username:password@host:port/database)\n",
    "\n",
    "# TTN Application:\n",
    "theApplication = ['addferti-rostock-soil-moisture','addferti-bursa-soil-moisture','addferti-ugent-soil-moisture']\n",
    "theAPIKey = ['NNSXS.5IXRRQ74V3NDRIMSP4RQ6FZ5W5CEGL5P6QN457Q.JOIUJJ5TYRJDCMMHTZMH7HBGTPVLTHYQYZUYXFMHHOQ2WGW5DL4Q',\n",
    "             'NNSXS.FC4XATDRAUL22VSYSZYB7XPJQXHLZI534GVKKAY.QM5FGNQX7B6DNWE4CVD5ZYUQ6HUFQP72KX5KWTOSNTIG4TTFJX6A',\n",
    "             'NNSXS.R7NNSNQE24QDNLJ7XIQD6CRBVYHCWO72C7E2REY.JN2I3FWELVV2E6CZCIAEKXNJVLB6DTJZ34JOPXMOSFTYL4PWP4DA']\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    # Note the path you have to specify. Double note that it has be prefixed with up.\n",
    "    theFields = \"up.uplink_message.decoded_payload,up.uplink_message.locations\"\n",
    "\n",
    "    theNumberOfRecords = 100\n",
    "\n",
    "    theURL = \"https://eu1.cloud.thethings.network/api/v3/as/applications/\" + theApplication[i] + \"/packages/storage/uplink_message?order=-received_at&limit=\" + str(theNumberOfRecords) + \"&field_mask=\" + theFields\n",
    "\n",
    "    # These are the headers required in the documentation.\n",
    "    theHeaders = { 'Accept': 'text/event-stream', 'Authorization': 'Bearer ' + theAPIKey[i] }\n",
    "\n",
    "    print(\"\\nFetching data from \",theApplication[i])\n",
    "\n",
    "    r = requests.get(theURL, headers=theHeaders)\n",
    "    #print(r.text)\n",
    "\n",
    "    print(\"URL: \" + r.url)\n",
    "    print(\"Status: \" + str(r.status_code))\n",
    "    \n",
    "    theJSON = \"{\\\"data\\\": [\" + r.text.replace(\"\\n\\n\", \",\")[:-1] + \"]}\";\n",
    "\n",
    "    df = pd.read_json(theJSON)\n",
    "    try:\n",
    "        normalized_df = pd.concat([pd.DataFrame(pd.json_normalize(x)) for x in df['data']],ignore_index=True)\n",
    "\n",
    "            #print(\"column headers:\")\n",
    "            #for col in normalized_df.columns:\n",
    "            #\t  print(col)\n",
    "            #-------------------------------------------\n",
    "            #result.end_device_ids.device_id                     --> Device ID\n",
    "            #result.received_at                                  --> Timestamp\n",
    "            #result.uplink_message.frm_payload\n",
    "            #result.uplink_message.decoded_payload.Bat\n",
    "            #result.uplink_message.decoded_payload.TempC_DS18B20\n",
    "            #result.uplink_message.decoded_payload.conduct_SOIL  --> Soil Conductivity (uS/cm) (mikroSiemens/cm)\n",
    "            #result.uplink_message.decoded_payload.temp_SOIL     --> Soil Temperature (Â°C)\n",
    "            #result.uplink_message.decoded_payload.water_SOIL    --> Soil Moisture (0-100%)\n",
    "            #result.uplink_message.received_at\n",
    "            #result.uplink_message.locations.user.latitude       --> Lat\n",
    "            #result.uplink_message.locations.user.longitude      --> Long\n",
    "            #-------------------------------------------\n",
    "\n",
    "        # subset of the normalized dataframe\n",
    "        df = normalized_df[[\n",
    "          \"result.end_device_ids.device_id\",\n",
    "          \"result.received_at\",\n",
    "          \"result.uplink_message.decoded_payload.conduct_SOIL\",\n",
    "          \"result.uplink_message.decoded_payload.temp_SOIL\",\n",
    "          \"result.uplink_message.decoded_payload.water_SOIL\",\n",
    "          \"result.uplink_message.locations.user.latitude\",\n",
    "          \"result.uplink_message.locations.user.longitude\"]]\n",
    "\n",
    "        #df = df.reset_index()\n",
    "\n",
    "        TTN_df = df.rename(columns={\n",
    "          \"result.end_device_ids.device_id\":                    \"device_id\",\n",
    "          \"result.received_at\":                                 \"time\",\n",
    "          \"result.uplink_message.decoded_payload.conduct_SOIL\": \"soil_ec\",\n",
    "          \"result.uplink_message.decoded_payload.temp_SOIL\":    \"soil_temp\",\n",
    "          \"result.uplink_message.decoded_payload.water_SOIL\":   \"soil_mc\",\n",
    "          \"result.uplink_message.locations.user.latitude\":      \"lat\",\n",
    "          \"result.uplink_message.locations.user.longitude\":     \"long\"})\n",
    "\n",
    "        TTN_df.time        = pd.to_datetime(TTN_df['time'])\n",
    "        TTN_df.time        = TTN_df.time.round('S')\n",
    "        TTN_df.soil_ec     = pd.to_numeric(TTN_df['soil_ec'])\n",
    "        TTN_df.soil_temp   = pd.to_numeric(TTN_df['soil_temp'])\n",
    "        TTN_df.soil_mc     = pd.to_numeric(TTN_df['soil_mc'])\n",
    "        TTN_df             = TTN_df[TTN_df['soil_temp'] != 0]\n",
    "        TTN_df.lat         = TTN_df.lat.round(8)\n",
    "        TTN_df.long        = TTN_df.long.round(8)\n",
    "        \n",
    "        #print(TTN_df.dtypes)\n",
    "        #print(\"Fetched data: \")\n",
    "        #print(TTN_df)\n",
    "\n",
    "        try:\n",
    "            postgreSQLConnection = alchemyEngine.connect();\n",
    "            TTN_df.to_sql(postgreSQLTable[i], postgreSQLConnection, index=False, if_exists='append');\n",
    "            SQL = (\"DELETE FROM %s t WHERE EXISTS (SELECT FROM %s WHERE device_id = t.device_id \" \n",
    "                   \"AND time = t.time AND ctid < t.ctid \"\n",
    "                   \"order by time);\")%(postgreSQLTable[i],postgreSQLTable[i])\n",
    "            postgreSQLConnection.execute(SQL)\n",
    "            \n",
    "        except TypeError:\n",
    "            print(\"create table\", postgreSQLTable[i])\n",
    "            TTN_df.to_sql(postgreSQLTable[i], postgreSQLConnection, index=False, if_exists='fail');\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Value Error. No Data from TTN to fetch for \" + postgreSQLTable[i])\n",
    "        pass\n",
    "    \n",
    "    finally:\n",
    "        postgreSQLConnection.close();\n",
    "\n",
    "## Export the current soil moisture data as a Shapefile\n",
    "## Upload to Geonode works through copying the new shapefiles in the Geoserver Docker Container\n",
    "## sudo docker cp /data/current_ru_soil_moisture geoserver4my_geonode:/geoserver_data/data/data/geonode\n",
    "## Also the Layer and the Store need to be created once (execute )\n",
    "for i in range(0,3):\n",
    "    postgreSQLTable = ['ru_soil_moisture','bursa_soil_moisture','ugent_soil_moisture']\n",
    "    alchemyEngine   = create_engine('postgresql+psycopg2://postgres:postgres@127.0.0.1:5432/addferti_lorawan', pool_recycle=3600);\n",
    "\n",
    "    SQL = (\"SELECT DISTINCT ON (device_id) \" \n",
    "           \" device_id, time, soil_temp, soil_mc, soil_ec, lat, long \"\n",
    "           \" FROM %s ORDER BY device_id, time desc;\")%(postgreSQLTable[i])\n",
    "    try:\n",
    "        df_c_smc = pd.read_sql(SQL,con=alchemyEngine)\n",
    "    except:\n",
    "        print(postgreSQLTable[i] + ' table not available.')\n",
    "    else:\n",
    "        folder = 'current_'+ postgreSQLTable[i]\n",
    "        isExist = os.path.exists(folder)\n",
    "        if not isExist:\n",
    "           # Create a new directory because it does not exist\n",
    "           os.makedirs(folder)\n",
    "\n",
    "        # Transform DataFrame into a GeoDataFrame\n",
    "        gdf = geopandas.GeoDataFrame(\n",
    "            df_c_smc, geometry=geopandas.points_from_xy(df_c_smc.long, df_c_smc.lat))\n",
    "\n",
    "        # Add projection\n",
    "        gdf.crs = 'epsg:4326'\n",
    "\n",
    "        # Transform python datetime object to an string (shapefile cant read datetime format)\n",
    "        gdf['time'] = gdf['time'].dt.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "        #print(gdf)\n",
    "        #gdf.plot()\n",
    "\n",
    "        # Export data to file\n",
    "        print('exporting: current_' + postgreSQLTable[i] + '.shp')\n",
    "        df.to_csv  (folder + '/current_' + postgreSQLTable[i]+'.csv')\n",
    "        gdf.to_file(folder + '/current_' + postgreSQLTable[i]+'.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673de551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
